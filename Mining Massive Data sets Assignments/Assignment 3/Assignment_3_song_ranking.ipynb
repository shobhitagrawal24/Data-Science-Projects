{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile as zf\n",
    "import json\n",
    "import time\n",
    "import scipy.sparse as sps\n",
    "from sklearn.preprocessing import normalize\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the parameters\n",
    "\n",
    "* fileName: The name of the database file\n",
    "* simCutoff: The minimum similarity there has to be for there to be a link between track i to j\n",
    "* tagCutoff: The minimum Tag value there has to be for there to be a link between a track and a particular Tag\n",
    "* Beta: The Beta value for $r^{new} = \\beta M r^{old} + A$\n",
    "* n_most_i: The parameter that defines n in \"Top n most popluar songs\"\n",
    "* tagList: The selected list of tags for this experiment. Note that The songs will be selected as an intersection of tags. IE: If the taglist is ['a', 'b'], then only the songs that have both 'a' and 'b' tags will be selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName = 'lastfm_test.zip'\n",
    "simCutoff = 0.0\n",
    "tagCutoff = 50\n",
    "Beta = 0.2\n",
    "n_most_i = 5\n",
    "tagList = ['Hip-Hop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  % of dataset loaded.\n",
      "8  % of dataset loaded.\n",
      "16  % of dataset loaded.\n",
      "25  % of dataset loaded.\n",
      "33  % of dataset loaded.\n",
      "41  % of dataset loaded.\n",
      "49  % of dataset loaded.\n",
      "57  % of dataset loaded.\n",
      "65  % of dataset loaded.\n",
      "74  % of dataset loaded.\n",
      "82  % of dataset loaded.\n",
      "90  % of dataset loaded.\n",
      "98  % of dataset loaded.\n",
      "Loading the dataset took  61.35269417968627  seconds.\n"
     ]
    }
   ],
   "source": [
    "begin = time.clock()\n",
    "simD = []\n",
    "tagD = []\n",
    "trkToIndex = {}\n",
    "tagToIndex = {}\n",
    "file = zf.ZipFile(fileName)\n",
    "trkCounter = count()\n",
    "tagCounter = count()\n",
    "\n",
    "for i in range(0,len(file.filelist)):\n",
    "    \n",
    "    if(i%10000 == 0):\n",
    "        print(round(100 * i / len(file.filelist)), \" % of dataset loaded.\")\n",
    "    \n",
    "    if(file.filelist[i].filename.endswith('.json')):\n",
    "        fCont = file.read(file.filelist[i]).decode(\"utf-8\")\n",
    "        jCont = json.loads(fCont)\n",
    "        \n",
    "        sims = np.array(jCont['similars'])\n",
    "        tags = np.array(jCont['tags'])\n",
    "        tName = jCont['track_id']\n",
    "        \n",
    "        if(tName in trkToIndex):\n",
    "            trkIndex = trkToIndex[tName]\n",
    "        else:\n",
    "            trkIndex = next(trkCounter)\n",
    "            trkToIndex[tName] = trkIndex\n",
    "        \n",
    "        for s in sims:\n",
    "            similarity = float(s[1])\n",
    "            \n",
    "            if((similarity >= simCutoff) & (similarity <= 1.0)):\n",
    "                tName2 = s[0]\n",
    "                \n",
    "                \n",
    "                if(tName2 in trkToIndex):\n",
    "                    trkIndex2 = trkToIndex[tName2]\n",
    "                else:\n",
    "                    trkIndex2 = next(trkCounter)\n",
    "                    trkToIndex[tName2] = trkIndex2\n",
    "                    \n",
    "                simD.append([trkIndex, trkIndex2])\n",
    "                \n",
    "        for t in tags:\n",
    "            tagCount = int(t[1])\n",
    "            \n",
    "            if(tagCount >= tagCutoff):\n",
    "                tagName = t[0]\n",
    "                \n",
    "                if(tagName in tagToIndex):\n",
    "                    tagIndex = tagToIndex[tagName]\n",
    "                else:\n",
    "                    tagIndex = next(tagCounter)\n",
    "                    tagToIndex[tagName] = tagIndex\n",
    "                    \n",
    "                tagD.append([trkIndex, tagIndex])\n",
    "                \n",
    "simD = np.array(list(set(tuple(sim) for sim in simD)))\n",
    "file.close()\n",
    "print(\"Loading the dataset took \", time.clock() - begin, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Adjacency and Tag matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the matrices for computation of R took  3.3804449745717235  seconds\n"
     ]
    }
   ],
   "source": [
    "begin = time.clock()\n",
    "simD = np.array(simD)\n",
    "\n",
    "X = simD[:,0].astype(np.int)\n",
    "Y = simD[:,1].astype(np.int)\n",
    "Z = np.ones(len(simD))\n",
    "\n",
    "mMat = sps.coo_matrix((Z,(Y,X)),shape=(len(trkToIndex),len(trkToIndex))).tocsc()\n",
    "normalize(mMat, norm='l1', axis=0, copy=False)\n",
    "\n",
    "tagD = np.array(tagD)\n",
    "\n",
    "X = tagD[:,0].astype(np.int)\n",
    "Y = tagD[:,1].astype(np.int)\n",
    "Z = np.ones(len(tagD))\n",
    "\n",
    "tagMat = sps.coo_matrix((Z,(Y,X))).tocsc()\n",
    "#To get \"from i to j\", plug in tagMat[j,i]\n",
    "\n",
    "del simD, tagD, X, Y\n",
    "print(\"Creating the matrices for computation of R took \", time.clock() - begin, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the songs that will be given a bias according to the tagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trkByTag = []\n",
    "\n",
    "for tagid in tagList:\n",
    "    trkByTag.append(set(tagMat[tagToIndex[tagid]].nonzero()[1]))\n",
    "trkByTag = np.array(list(set.intersection(*trkByTag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating through the $r^{new} = \\beta M r^{old} + A$ to find the r matrix\n",
    "\n",
    "* Please note the code \"rNew += iMat * probDiff / N\". This is done because in the M matrix, there are many columns that have no adjacencies. That means the column sum of those columsn don't add up to 1. This causes the sum of r matrix to be less than 0. IE: there remains a small probability that is not distributed amongst the dataset.\n",
    "\n",
    "* This is normally tackled by removing the 0 columns and their corresponding rows from the M matrix. But we can't do that because to do that, we would need to spend a lot of computation time in reassigning the remaining indexes to remaining track ids in trkToIndex dictionary.\n",
    "\n",
    "* One hack that works perfectly fine is giving $\\frac{1}{N}$ probability to all entries of 0 columns. We also can't do that because: 1- It takes too much time to edit the M matrix. 2- That reduces the sparsity of our M matrix, so the rest of the computations become expensive as well.\n",
    "\n",
    "* Instead, we implemented a workaround in the $\\frac{1}{N}$ probability hack. At the end of each iteration, we calculate $1 - ||r||$, and divide this amongst all the values in r. That is because if we used the $\\frac{1}{N}$ probability hack, these probabilites would have already be assigned in r matrix accordingly. Doing so, we're fixing the probability loss in an effective and efficient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59531893905 1.0 1.0 0.000563593952689\n",
      "\n",
      "0.0486634057893 1.0 1.0 0.000587570169797\n",
      "\n",
      "0.000234524792369 1.0 1.0 0.000587691244906\n",
      "\n",
      "1.29050777275e-06 1.0 1.0 0.000587691831623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "begin = time.clock()\n",
    "\n",
    "aMat = sps.lil_matrix((mMat.shape[0],1))\n",
    "aMat[trkByTag,:] = (1 - Beta) / len(trkByTag)\n",
    "\n",
    "iMat = sps.csc_matrix(np.ones(mMat.shape[0])).T\n",
    "\n",
    "N = aMat.shape[0]\n",
    "rOld = sps.coo_matrix(np.ones(N)*(1/N)).T.tocsc()\n",
    "\n",
    "mMat = mMat * Beta\n",
    "difference = 1\n",
    "\n",
    "while(difference > 0.0001):\n",
    "    \n",
    "    rNew = (mMat).dot(rOld) + aMat\n",
    "    probDiff = 1 - rNew.sum()\n",
    "    rNew += iMat * probDiff / N\n",
    "    \n",
    "    difference = np.abs(rNew - rOld).sum()\n",
    "    rOld = rNew.copy()\n",
    "    \n",
    "print(\"Computing the r matrix took \", time.clock() - begin, \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the top n highe values in r that correspond to the tagList and extracting the song names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selMat = np.array([np.array([trkByTag]), np.array(rNew[trkByTag].toarray()).T]).T\n",
    "selMat = selMat.reshape(selMat.shape[0],selMat.shape[2])\n",
    "selMat = sorted(selMat, key=lambda smE: smE[1])\n",
    "MIT = np.array(selMat[-n_most_i-1:-1])[:,0].astype(np.int)\n",
    "trkNameList = []\n",
    "for trk in trkToIndex:\n",
    "    if(trkToIndex[trk] in MIT):\n",
    "        trkNameList.append(trk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most influential tracks for the tag(s)  ['Hip-Hop', 'Hip-Hop']  are:\n",
      "\n",
      "TRVXYAU128F428B84B\n",
      "TRFOVKJ128F92C3021\n",
      "TRCCEXX128F4292E09\n",
      "TRNGVCV128F149F339\n",
      "TRGRONS128E0786070\n"
     ]
    }
   ],
   "source": [
    "print(\"The most influential tracks for the tag(s) \", tagList, \" are:\\n\")\n",
    "for i in trkNameList:\n",
    "    print(i)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
