{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on results:\n",
    "With the SGD, we receive worse results than GD as expected but SGD runs much faster and can handle much larger datasets.\n",
    "\n",
    "With GD, we can deal with 500.000 data points but it takes A LOT of time to fit.\n",
    "\n",
    "With SGD batch size 1, we can deal with over 1.500.000 data points but the results are not really satisfactory.\n",
    "\n",
    "With SGD batch size 1000, we can deal with 1.500.000 data points and the results are beter than SGD batch size 1\n",
    "\n",
    "Also, with SGD, the loss and error function maps are quite unpredictable compared to the constantly decreasing function received from GD. That is because with SGD, it is possible that in each iteration we randomly select a bad sample that causes divergence. Which will lead to ups and downs in the loss and RMSE graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse.linalg import svds\n",
    "import scipy.linalg as lalg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binning(x, bns):\n",
    "    for b in bns:\n",
    "        if((x >= b[0]) & (x <= b[1])):\n",
    "            return b[2]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadData(fname, B, N):\n",
    "    i = 0\n",
    "    data = []\n",
    "    uid = -1\n",
    "    una = ''\n",
    "    \n",
    "    bins = [[np.power(2,i), np.power(2,(i + 1)) - 1, i + 1] for i in range(B)]\n",
    "    bins[len(bins) - 1][1] = np.infty\n",
    "    \n",
    "    with open(fname) as FileObj:\n",
    "        for line in FileObj:\n",
    "            if(i >= N):\n",
    "                break\n",
    "            a = line.split('\\t')\n",
    "\n",
    "            if(a[0] != una):\n",
    "                uid += 1\n",
    "                una = a[0]\n",
    "\n",
    "            data.append([uid, int(a[1],36), binning(int(a[2]),bins)])\n",
    "            i+=1\n",
    "    data = np.array(data)\n",
    "    data = data[data[:,1].argsort()]\n",
    "    sid = -1\n",
    "    sti = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if(sti != data[i][1]):\n",
    "            sti = data[i][1]\n",
    "            sid += 1\n",
    "        data[i][1] = sid\n",
    "\n",
    "    M = sps.coo_matrix((data[:,2],(data[:,0],data[:,1])), dtype=np.float).tocsr()\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def refineData(M,cutoff):\n",
    "    carryOn = True\n",
    "\n",
    "    while(carryOn):\n",
    "\n",
    "        carryOn = False\n",
    "        NZ = M.nonzero()\n",
    "\n",
    "        sList, sCount = np.unique(NZ[1],return_counts=True)\n",
    "        keepSongs = np.sort(sList[sCount > cutoff])\n",
    "\n",
    "        if(len(keepSongs) < len(sList)):\n",
    "            carryOn = True\n",
    "            M = M[:,keepSongs]\n",
    "\n",
    "        uList, uCount = np.unique(NZ[0],return_counts=True)\n",
    "        keepUsers = np.sort(uList[uCount > cutoff])\n",
    "\n",
    "        if(len(keepUsers) < len(uList)):\n",
    "            carryOn = True\n",
    "            M = M[keepUsers,:]\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divDS(M, divS):\n",
    "    NZ = M.nonzero()\n",
    "    ss = random.sample(range(len(NZ[0])), divS)\n",
    "    \n",
    "    valSet = []\n",
    "    for s in ss:\n",
    "        i = NZ[0][s]\n",
    "        j = NZ[1][s]\n",
    "        valSet.append([i,j,M[i,j]])\n",
    "        M[i,j] = 0\n",
    "    \n",
    "    return valSet,M\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradientDescent(M,Q,P,valSet,lRate,lambda1,lambda2,maxIter=50):\n",
    "    print(\"Applying regular gradient descent\")\n",
    "    print(\"\\t\\tTraining RMSE\\tValidation RMSE\")\n",
    "    NZ = M.nonzero()\n",
    "    NZS = len(NZ[0])\n",
    "\n",
    "    val_e = []\n",
    "    tr_e = []\n",
    "    val_l = []\n",
    "    tr_l = []\n",
    "    V_s = len(valSet)\n",
    "    lve = np.infty\n",
    "\n",
    "    for itr in range(1, maxIter+1):\n",
    "\n",
    "        val_p = -1\n",
    "        tra_p = -1\n",
    "\n",
    "        Q_p = Q.copy()\n",
    "        P_p = P.copy()\n",
    "\n",
    "        Q_e = np.zeros(Q.shape)\n",
    "        P_e = np.zeros(P.shape)\n",
    "\n",
    "        error = 0\n",
    "        p1 = 0\n",
    "        p2 = 0\n",
    "        \n",
    "        for nz in range(NZS):\n",
    "            i = NZ[0][nz]\n",
    "            x = NZ[1][nz]\n",
    "\n",
    "            e = M[i,x] - np.dot(Q[:,i], P[:,x])\n",
    "\n",
    "            p_e = -e * Q[:,i] + lambda1 * P[:,x]\n",
    "            q_e = -e * P[:,x] + lambda2 * Q[:,i]\n",
    "\n",
    "            Q_e[:,i] -= q_e * lRate\n",
    "            P_e[:,x] -= p_e * lRate\n",
    "            \n",
    "            error += e*e\n",
    "            p1 += np.sum(Q[:,NZ[0][nz]] * Q[:,NZ[0][nz]])\n",
    "            p2 += np.sum(P[:,NZ[1][nz]] * P[:,NZ[1][nz]])\n",
    "\n",
    "        Q = Q + Q_e\n",
    "        P = P + P_e\n",
    "\n",
    "        tr_e.append(np.sqrt(error/NZS))\n",
    "        tr_l.append((error + lambda1 * p1 + lambda2 * p2) / NZS)\n",
    "\n",
    "        print(\"iteration\", itr,\":  \", np.sqrt(error/NZS),end=\"\\t\")\n",
    "\n",
    "        error = 0\n",
    "        p1 = 0\n",
    "        p2 = 0\n",
    "\n",
    "        for n in range(V_s):\n",
    "            e = valSet[n][2] - np.dot(Q[:,valSet[n][0]], P[:,valSet[n][1]])\n",
    "            error += e*e\n",
    "            p1 += np.sum(Q[:,NZ[0][nz]] * Q[:,NZ[0][nz]])\n",
    "            p2 += np.sum(P[:,NZ[1][nz]] * P[:,NZ[1][nz]])\n",
    "\n",
    "        val_e.append(np.sqrt(error/V_s))\n",
    "        val_l.append((error + lambda1 * p1 + lambda2 * p2) / V_s)\n",
    "\n",
    "        print(np.sqrt(error/V_s))\n",
    "\n",
    "        if(lve < np.sqrt(error/V_s)):\n",
    "            break\n",
    "        lve = np.sqrt(error/V_s)\n",
    "\n",
    "    print(\"Regular gradient descent ended in\",itr,\"iterations\")\n",
    "    \n",
    "    if(itr == maxIter + 1):\n",
    "        return Q,P,val_e,tr_e,val_l,tr_l\n",
    "\n",
    "    val_e.pop()\n",
    "    tr_e.pop()\n",
    "    \n",
    "    val_l.pop()\n",
    "    tr_l.pop()\n",
    "    \n",
    "    return Q_p,P_p,val_e,tr_e,val_l,tr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochasticGradientDescent(M,Q,P,valSet,lRate,lambda1,lambda2,batchSize=1,maxIter=500):\n",
    "    print(\"Applying stochastic gradient descent with batch size\", batchSize)\n",
    "    print(\"\\t\\tTraining RMSE\\tValidation RMSE\")\n",
    "    NZ = M.nonzero()\n",
    "    NZS = len(NZ[0])\n",
    "\n",
    "    val_e = []\n",
    "    tr_e = []\n",
    "    val_l = []\n",
    "    tr_l = []\n",
    "    V_s = len(valSet)\n",
    "    lve = np.infty\n",
    "    \n",
    "    sList, sCount = np.unique(NZ[0],return_counts=True)\n",
    "    uList, uCount = np.unique(NZ[1],return_counts=True)\n",
    "    \n",
    "    TR = random.sample(range(NZS), NZS)\n",
    "\n",
    "    for itr in range(0, maxIter):\n",
    "\n",
    "        val_p = -1\n",
    "        tra_p = -1\n",
    "\n",
    "        Q_p = Q.copy()\n",
    "        P_p = P.copy()\n",
    "\n",
    "        Q_e = np.zeros(Q.shape)\n",
    "        P_e = np.zeros(P.shape)\n",
    "\n",
    "        trv = TR[(itr*batchSize)%NZS:((itr+1)*batchSize)%NZS]\n",
    "        \n",
    "        error = 0\n",
    "        p1 = 0\n",
    "        p2 = 0\n",
    "        \n",
    "        for nz in range(len(trv)):\n",
    "            i = NZ[0][trv[nz]]\n",
    "            x = NZ[1][trv[nz]]\n",
    "            \n",
    "            e = M[i,x] - np.dot(Q[:,i], P[:,x])\n",
    "\n",
    "            p_e = -e * Q[:,i] + lambda1 * P[:,x]\n",
    "            q_e = -e * P[:,x] + lambda2 * Q[:,i]\n",
    "\n",
    "            Q_e[:,i] -= q_e * lRate * uCount[i] / NZS\n",
    "            P_e[:,x] -= p_e * lRate * sCount[i] / NZS\n",
    "            \n",
    "            error += e*e\n",
    "            p1 += np.sum(Q[:,NZ[0][nz]] * Q[:,NZ[0][nz]])\n",
    "            p2 += np.sum(P[:,NZ[1][nz]] * P[:,NZ[1][nz]])\n",
    "           \n",
    "        tr_e.append(np.sqrt(error/NZS))\n",
    "        tr_l.append((error + lambda1 * p1 + lambda2 * p2) / NZS)\n",
    "        \n",
    "        Q = Q + Q_e\n",
    "        P = P + P_e\n",
    "    \n",
    "        print(\"iteration\", itr,\":  \", np.sqrt(error/NZS),end=\"\\t\")\n",
    "        error = 0\n",
    "        p1 = 0\n",
    "        p2 = 0\n",
    "\n",
    "        for n in range(V_s):\n",
    "            e = valSet[n][2] - np.dot(Q[:,valSet[n][0]], P[:,valSet[n][1]])\n",
    "            error += e*e\n",
    "            p1 += np.sum(Q[:,NZ[0][nz]] * Q[:,NZ[0][nz]])\n",
    "            p2 += np.sum(P[:,NZ[1][nz]] * P[:,NZ[1][nz]])\n",
    "\n",
    "        val_e.append(np.sqrt(error/V_s))\n",
    "        val_l.append((error + lambda1 * p1 + lambda2 * p2) / V_s)        \n",
    "        \n",
    "        print(np.sqrt(error/V_s))\n",
    "            \n",
    "        lve = np.sqrt(error/V_s)\n",
    "\n",
    "    print(\"Stochastic gradient descent ended in\",itr,\"iterations\")\n",
    "    \n",
    "    if(itr == maxIter - 1):\n",
    "        return Q,P,val_e,tr_e,val_l,tr_l\n",
    "\n",
    "    val_e.pop()\n",
    "    tr_e.pop()\n",
    "    \n",
    "    val_l.pop()\n",
    "    tr_l.pop()\n",
    "    \n",
    "    return Q_p,P_p,val_e,tr_e,val_l,tr_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA, REFINE QP DECOMPOSITION ETC..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"train_triplets.txt\"\n",
    "N = 300000\n",
    "V_s = 1000\n",
    "T_s = 200\n",
    "cutoff = 5\n",
    "B = 10\n",
    "K = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = loadData(fname, B, N)\n",
    "M = refineData(M, cutoff)\n",
    "valSet, M = divDS(M, V_s)\n",
    "testSet, M = divDS(M, T_s)\n",
    "\n",
    "U, s, V = svds(M, k=K)\n",
    "S = lalg.sqrtm(np.diag(s))\n",
    "Q = U.dot(S)\n",
    "Q = Q.transpose()\n",
    "P = S.dot(V)\n",
    "Q_bck = Q.copy()\n",
    "P_bck = P.copy()\n",
    "\n",
    "lRate = 0.005\n",
    "lambda2 = 0.02\n",
    "lambda1 = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "begin = time.clock()\n",
    "Q,P,val_e,tr_e,val_l,tr_l = gradientDescent(M,Q,P,valSet,lRate,lambda1,lambda2)\n",
    "print(\"Regular gradient descent took\", time.clock() - begin, \"seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = 0\n",
    "for n in range(T_s):\n",
    "    e = testSet[n][2] - np.dot(Q[:,testSet[n][0]], P[:,testSet[n][1]])\n",
    "    error += e*e\n",
    "error = np.sqrt(error/T_s)\n",
    "print(\"Testing RMSE:\",error)\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Training')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Validation')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "plt.plot(range(len(tr_l)),tr_l, 'r')\n",
    "plt.plot(range(len(val_l)),val_l, 'b')\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Training')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Validation')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "plt.plot(range(len(tr_e)),tr_e, 'r')\n",
    "plt.plot(range(len(val_e)),val_e, 'b')\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent with batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q = Q_bck.copy()\n",
    "P = P_bck.copy()\n",
    "begin = time.clock()\n",
    "Q,P,val_e,tr_e,val_l,tr_l = stochasticGradientDescent(M,Q,P,valSet,lRate,lambda1,lambda2,batchSize=1)\n",
    "print(\"Stochastic gradient descent with batch size 1 took\", time.clock() - begin, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error = 0\n",
    "for n in range(T_s):\n",
    "    e = testSet[n][2] - np.dot(Q[:,testSet[n][0]], P[:,testSet[n][1]])\n",
    "    error += e*e\n",
    "error = np.sqrt(error/T_s)\n",
    "print(\"Testing RMSE:\",error)\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Training')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Validation')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "plt.plot(range(len(tr_l)),tr_l, 'r')\n",
    "plt.plot(range(len(val_l)),val_l, 'b')\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Training')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Validation')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "plt.plot(range(len(tr_e)),tr_e, 'r')\n",
    "plt.plot(range(len(val_e)),val_e, 'b')\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent with batch size 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q = Q_bck.copy()\n",
    "P = P_bck.copy()\n",
    "\n",
    "begin = time.clock()\n",
    "Q,P,val_e,tr_e,val_l,tr_l = stochasticGradientDescent(M,Q,P,valSet,lRate,lambda1,lambda2,batchSize=1000)\n",
    "print(\"Stochastic gradient descent with batch size 1 took\", time.clock() - begin, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = 0\n",
    "for n in range(T_s):\n",
    "    e = testSet[n][2] - np.dot(Q[:,testSet[n][0]], P[:,testSet[n][1]])\n",
    "    error += e*e\n",
    "error = np.sqrt(error/T_s)\n",
    "print(\"Testing RMSE:\",error)\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Training')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Validation')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "plt.plot(range(len(tr_l)),tr_l, 'r')\n",
    "plt.plot(range(len(val_l)),val_l, 'b')\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()\n",
    "\n",
    "red_patch = mpatches.Patch(color='red', label='Training')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Validation')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "plt.plot(range(len(tr_e)),tr_e, 'r')\n",
    "plt.plot(range(len(val_e)),val_e, 'b')\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
